<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Voice Chat Assistant</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f4f4f4;
      padding: 20px;
    }
    #chat {
      max-width: 600px;
      margin: auto;
      background: white;
      border-radius: 10px;
      padding: 20px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
      height: 70vh;
      overflow-y: auto;
    }
    .msg {
      margin-bottom: 12px;
      display: flex;
    }
    .user {
      justify-content: flex-end;
    }
    .user .bubble {
      background-color: #dcf8c6;
      align-self: flex-end;
    }
    .agent {
      justify-content: flex-start;
    }
    .agent .bubble {
      background-color: #e2e2e2;
      align-self: flex-start;
    }
    .bubble {
      padding: 10px;
      border-radius: 10px;
      max-width: 70%;
      word-wrap: break-word;
      white-space: pre-wrap;
    }
    #start, #stop {
      padding: 10px 20px;
      margin: 10px 5px;
      font-size: 16px;
    }
  </style>
</head>
<body>

  <div id="chat"></div>
  <div style="text-align: center;">
    <button id="start">ðŸŽ¤ Connect</button>
    <button id="stop" disabled>ðŸ”´ Disconnect</button>
  </div>

  <script>
    const chat = document.getElementById('chat');
    let socket, audioContext, processor, mediaStream, source;
    let audioQueue = [];
    let isPlaying = false;
    let currentSource = null; 

    function scrollToBottom() {
      chat.scrollTop = chat.scrollHeight;
    }

    function appendMessage(text, sender, typingEffect = false, callback = null) {
      const msg = document.createElement('div');
      msg.className = `msg ${sender}`;
      const bubble = document.createElement('div');
      bubble.className = 'bubble';
      msg.appendChild(bubble);
      chat.appendChild(msg);
      scrollToBottom();

      if (typingEffect) {
        let index = 0;
        const interval = setInterval(() => {
          bubble.textContent += text.charAt(index);
          index++;
          scrollToBottom();
          if (index >= text.length) {
            clearInterval(interval);
            if (callback) callback();
          }
        }, 30);
      } else {
        bubble.textContent = text;
        if (callback) callback();
      }
    }

    document.getElementById('start').onclick = async () => {
      // Resume AudioContext
      if (!audioContext || audioContext.state === 'suspended') {
        audioContext = new AudioContext();
        await audioContext.resume();
      }

      // ðŸ”‡ Stop any TTS currently playing
      if (currentSource) {
        try {
          currentSource.stop();
          currentSource = null;
          isPlaying = false;
          audioQueue = []; // Optional: clear any pending audio
        } catch (err) {
          console.warn('Failed to stop previous audio:', err.message);
        }
      }

      // Setup WebSocket
      const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
      socket = new WebSocket(`${protocol}//${location.host}`);
      socket.binaryType = 'arraybuffer';

      socket.onopen = async () => {
        audioContext = new AudioContext();
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });

        await audioContext.audioWorklet.addModule('processor.js');
        source = audioContext.createMediaStreamSource(mediaStream);
        processor = new AudioWorkletNode(audioContext, 'audio-capture');
        source.connect(processor).connect(audioContext.destination);
        socket.send('__welcome__');
        processor.port.onmessage = (event) => {
          if (socket.readyState === WebSocket.OPEN) {
            socket.send(event.data);
          }
          
          // ðŸ›‘ Stop TTS if user starts speaking
          // if (isPlaying && currentSource) {
           
          //   try {
          //     currentSource.stop(); // Stop current audio
          //     currentSource = null;
          //     isPlaying = false;
          //     audioQueue = [];      // Optional: cancel future TTS audio
          //     console.log('ðŸ›‘ TTS audio interrupted by user speech');
          //   } catch (e) {
          //     console.warn('Failed to stop audio on user speech:', e.message);
          //   }
          // }
        };

        document.getElementById('start').disabled = true;
        document.getElementById('stop').disabled = false;
      };

      socket.onmessage = async (event) => {
        if (typeof event.data === 'string') {
          const data = JSON.parse(event.data);
          
           
            
          if (data.type === 'QnA') {
          if (data.question != '')
          {
            // ðŸ›‘ Stop any audio already playing 
            if (currentSource) {
              try {
                currentSource.stop();
                currentSource = null;
                audioQueue = [];
                isPlaying = false;
                console.log('ðŸ›‘ Previous audio stopped due to new response');
              } catch (e) {
                console.warn('Error stopping previous audio:', e.message);
              }
            }
              appendMessage(data.question, 'user');
          }
            if (data.answer != '' )
              appendMessage(data.answer, 'agent', true, () => {
            
            });
          }

          if (data.type === 'ConversationText' && data.role === 'user') {
            alert(1);
            appendMessage(data.content, 'user');
          }

          if (data.type === 'ConversationText' && data.role === 'assistant') {
            alert(1);
            appendMessage(data.content, 'agent');
          }
        } else {
          try {


            const buffer = event.data; // Already an ArrayBuffer
            audioQueue.push(buffer); // Add to queue
            playNextInQueue();       // Trigger playback if not already



            // const audioBuffer = await audioContext.decodeAudioData(event.data);
            // const sourceNode = audioContext.createBufferSource();
            // sourceNode.buffer = audioBuffer;
            // sourceNode.connect(audioContext.destination);
            // sourceNode.start();
          } catch (err) {
            console.warn('Audio decode/playback failed:', err.message);
          }
        }
      };

      socket.onclose = () => {
        appendMessage("ðŸ”Œ Disconnected from assistant.", 'agent');
        document.getElementById('start').disabled = false;
        document.getElementById('stop').disabled = true;
      };
    };


  async function playNextInQueue() {
  if (isPlaying || audioQueue.length === 0) return;

  isPlaying = true;
  const buffer = audioQueue.shift();

  try {
    if (audioContext.state === 'suspended') {
      await audioContext.resume();
    }

    const audioBuffer = await audioContext.decodeAudioData(buffer);
    const source = audioContext.createBufferSource();
    const gainNode = audioContext.createGain();
    gainNode.gain.value = 1.5;
    currentSource = source;
    source.buffer = audioBuffer;
    source.connect(gainNode).connect(audioContext.destination);

    source.onended = () => {
      isPlaying = false;
      playNextInQueue(); // Play next in line
    };

      source.start();
    } catch (e) {
      console.warn('Audio playback failed:', e.message);
      isPlaying = false;
      playNextInQueue(); // Try next
    }
  }

    document.getElementById('stop').onclick = () => {
      if (processor) processor.disconnect();
      if (source) source.disconnect();
      if (mediaStream) mediaStream.getTracks().forEach(track => track.stop());
      if (socket && socket.readyState === WebSocket.OPEN) socket.close();
    };
  </script>

</body>
</html>
